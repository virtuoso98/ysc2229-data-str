{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A0149963M \n",
    "## YSC 2229 - Assignment 3 Solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "In this problem, we are required to implement the randomized solution of the vertex cover problem. The input of this function is a a graph consisting of nodes and edges, represented by an open hash table. Therefore, it becomes very sensible to implement a Node and Linked List before starting on this problem. Below shows my implementation of these 2 basic data structures. In addition, there is also a mini-sanity check to ensure that this implementation works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data = None, next = None):\n",
    "        self.data = data\n",
    "        self.next = None\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.data\n",
    "    \n",
    "class LinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        \n",
    "    def insert(self, data):\n",
    "        new = Node(data)\n",
    "        new.next = self.head\n",
    "        self.head = new\n",
    "    \n",
    "    def display(self):\n",
    "        head = self.head\n",
    "        while head:\n",
    "            print(head.data, \"->\", end=\" \")\n",
    "            head = head.next\n",
    "        print(\"end\")\n",
    "        \n",
    "    def search(self, x):\n",
    "        curr = self.head\n",
    "        while curr != None: \n",
    "            if curr.data == x:\n",
    "                print(\"Match Found, Returning Pointer\")\n",
    "                return curr\n",
    "            curr = curr.next\n",
    "        print(\"Match not Found. Returning None\")\n",
    "        return curr\n",
    "        \n",
    "    \n",
    "    def delete(self, x):\n",
    "        curr = self.head\n",
    "        prev = None\n",
    "        while curr and curr.data != x:\n",
    "            prev = curr\n",
    "            curr = curr.next\n",
    "        if not Node:\n",
    "            return None\n",
    "        else:\n",
    "            remove = curr.data\n",
    "            if not prev:\n",
    "                self.head = curr.next\n",
    "            else: \n",
    "                prev.next = prev.next.next\n",
    "            return remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code block, we test some cases of the Linked List. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 -> 6 -> 3 -> end\n"
     ]
    }
   ],
   "source": [
    "# test insert and display\n",
    "\n",
    "l = LinkedList()\n",
    "l.insert(3)\n",
    "l.insert(6)\n",
    "l.insert(9)\n",
    "l.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching 9...\n",
      "Match Found, Returning Pointer\n",
      "\n",
      "Searching 6...\n",
      "Match Found, Returning Pointer\n",
      "\n",
      "Searching 3...\n",
      "Match Found, Returning Pointer\n",
      "\n",
      "Searching 10...\n",
      "Match not Found. Returning None\n",
      "\n",
      "Searching 999...\n",
      "Match not Found. Returning None\n"
     ]
    }
   ],
   "source": [
    "# test search \n",
    "print(\"\\nSearching 9...\")\n",
    "l.search(9)\n",
    "print(\"\\nSearching 6...\")\n",
    "l.search(6)\n",
    "print(\"\\nSearching 3...\")\n",
    "l.search(3)\n",
    "\n",
    "# Values that don't exist in the linked list\n",
    "print(\"\\nSearching 10...\")\n",
    "l.search(10)\n",
    "print(\"\\nSearching 999...\")\n",
    "l.search(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 -> 17 -> 10 -> 9 -> 6 -> 3 -> end\n"
     ]
    }
   ],
   "source": [
    "# appending more elements before testing delete\n",
    "\n",
    "l.insert(10)\n",
    "l.insert(17)\n",
    "l.insert(20)\n",
    "l.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 -> 10 -> 9 -> 6 -> 3 -> end\n"
     ]
    }
   ],
   "source": [
    "# testing deleting of head\n",
    "l.delete(20)\n",
    "l.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 -> 10 -> 9 -> 6 -> end\n"
     ]
    }
   ],
   "source": [
    "# testing deleting of tail\n",
    "l.delete(3)\n",
    "l.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 -> 9 -> 6 -> end\n"
     ]
    }
   ],
   "source": [
    "# testing deleting of middle element\n",
    "l.delete(10)\n",
    "l.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to implement the Graph. The Graph is supposed to be an open hash table. However, we need to consider for the case for when the vertice number is very high (100000) yet only a few edges are filled. It would be a waste of memory space to simply generate empty linked lists for these edges. Hence, we will use an open hash to address this, where the keys are the slots. These slots then map to a linked list. Each node contains information as follows **(vertice, edge)** (e.g. (3, (3, 5)) is legitimate but (4, (8, 10)) is not because 4 is not a vertice in this edge.\n",
    "\n",
    "In the graph, you can then insert edges as per normal: **(a, b)**. My algorithm would automatically parse this into a suitable data type for the linked list. With that in my mind, please ensure that a < b as far as possible, since that is how I defined my function. \n",
    "\n",
    "In addition, I have also defined a Search function that searches takes in an edge and searchs for the corresponding edge in the Graph. Since (4, (4, 7)) is the same as (7, (4, 7)), I've included provisions for both possibilities. However, if you expect this edge to appear but is not found, please input (7, 4) instead and check whether there is such a value corresponding to the Graph. I've ignored the opposite way of writing the tuples since this graph is undirected and does not require too much attention. \n",
    "\n",
    "Next, I have a display function that helps to visualize the linked list in each node. Run it without any arguments if you want to see what the graph looks like.\n",
    "\n",
    "Last but not least, I have the **generate** function, which helps to generate a random graph with inputs n numbers of vertices and a maximum of m number of edges. This function generates unique edges (a, b) where a < b, so you so not have to worry about repeated edges. Just input your desired number of vertices and (max) edges and run it.\n",
    "\n",
    "\n",
    "The aforementioned functions are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random    \n",
    "    \n",
    "class Graph:\n",
    "    def __init__(self, slots):\n",
    "        # Initializing Open Hash\n",
    "        self.hash = {i: LinkedList() for i in range(slots)}\n",
    "        self.slots = slots\n",
    "    \n",
    "    def insert(self, edge):\n",
    "        \"\"\"\n",
    "        edge - Edge that the user desires to insert\n",
    "        in the open Hash Table\n",
    "        \"\"\"\n",
    "        slot = edge[0] % self.slots        \n",
    "        self.hash[slot].insert((edge[0], edge))\n",
    "    \n",
    "    def search(self, edge):\n",
    "        \"\"\"\n",
    "        edge - Edge that the user desires to find \n",
    "        in the open Hash Table\n",
    "        \"\"\"\n",
    "        # find first possibility \n",
    "        slot = edge[0] % self.slots \n",
    "        curr = self.hash[slot].head\n",
    "        while curr:\n",
    "            if (edge[0], edge) == curr.data:\n",
    "                print(\"Match found, returning pointer for\", edge)\n",
    "                return curr\n",
    "            curr = curr.next\n",
    "        \n",
    "        # find second possibility \n",
    "        slot = edge[1] % self.slots \n",
    "        curr = self.hash[slot].head\n",
    "        while curr:\n",
    "            if (edge[1], edge) == curr.data:\n",
    "                print(\"Alternative Match found, returning pointer for\", edge)\n",
    "                return curr\n",
    "            curr = curr.next\n",
    "        \n",
    "        print(\"Match not found, returning None for\", edge)\n",
    "        return\n",
    "        \n",
    "    def generate(self, m_vertice, n_edges_max):\n",
    "        \"\"\"\n",
    "        Generates a maximum of n random edges for \n",
    "        m vertices to create a graph that can be \n",
    "        tested with.\n",
    "        \n",
    "        m_vertices - number of vertices\n",
    "        n_edges_max - maximum number of edges created\n",
    "        \"\"\"\n",
    "        x = set()\n",
    "        for i in range(n_edges_max):\n",
    "            low = random.randint(0, m_vertice - 1)\n",
    "            high = random.randint(low + 1, m_vertice)\n",
    "            edge = (low, high)\n",
    "            if edge in x:\n",
    "                continue\n",
    "            else:\n",
    "                x.add(edge)\n",
    "                self.insert(edge)\n",
    "                \n",
    "    def display(self):\n",
    "        \"\"\"\n",
    "        Prints the Open Hash Table for easy visualization\n",
    "        \"\"\"\n",
    "        for i in range(self.slots):\n",
    "            curr = self.hash[i].head\n",
    "            print(\"\\nPrinting Vertices and Edges for Slot Number\", i)\n",
    "            while curr:\n",
    "                print(curr.data, \" -> \", end = \" \")\n",
    "                curr = curr.next\n",
    "            print(\"end\", end = \"\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 2 code blocks demonstrate the capabilities of my function:\n",
    "* For the graph initaialization function, simply add the number of slots you want in the Linked List.\n",
    "* For the insert function, add your desired edge as a tuple. There is no restriction, just that the values in the edges must be integers.\n",
    "* For the search function, search your desired edge as a tuple. If that doesn't work, consider swapping the values.\n",
    "* For the generate function, add in your desired number of vertices and maximum number of edges and run it. Please ensure that this graph is empty!\n",
    "\n",
    "Feel free to change the values to your satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found, returning pointer for (3, 4)\n",
      "Match not found, returning None for (6, 8)\n"
     ]
    }
   ],
   "source": [
    "g = Graph(10)\n",
    "g.insert((3, 4))\n",
    "g.search((3, 4))\n",
    "g.search((6, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing Vertices and Edges for Slot Number 0\n",
      "(5, (5, 16))  ->  (0, (0, 2))  ->  (20, (20, 23))  ->  (15, (15, 23))  ->  (5, (5, 20))  ->  (10, (10, 18))  ->  (15, (15, 25))  ->  (10, (10, 14))  ->  end\n",
      "Printing Vertices and Edges for Slot Number 1\n",
      "(1, (1, 19))  ->  (16, (16, 19))  ->  (6, (6, 13))  ->  (11, (11, 15))  ->  (16, (16, 17))  ->  (21, (21, 23))  ->  (21, (21, 24))  ->  (21, (21, 22))  ->  (6, (6, 21))  ->  (6, (6, 9))  ->  (6, (6, 14))  ->  end\n",
      "Printing Vertices and Edges for Slot Number 2\n",
      "(2, (2, 16))  ->  (2, (2, 19))  ->  (17, (17, 20))  ->  (2, (2, 9))  ->  (7, (7, 21))  ->  (12, (12, 24))  ->  (12, (12, 23))  ->  (17, (17, 25))  ->  (22, (22, 24))  ->  (7, (7, 20))  ->  (2, (2, 3))  ->  (22, (22, 25))  ->  (2, (2, 23))  ->  end\n",
      "Printing Vertices and Edges for Slot Number 3\n",
      "(23, (23, 24))  ->  (13, (13, 20))  ->  (23, (23, 25))  ->  end\n",
      "Printing Vertices and Edges for Slot Number 4\n",
      "(4, (4, 20))  ->  (9, (9, 11))  ->  (9, (9, 25))  ->  (19, (19, 21))  ->  (19, (19, 23))  ->  (14, (14, 15))  ->  (14, (14, 17))  ->  (14, (14, 19))  ->  (9, (9, 23))  ->  (4, (4, 14))  ->  end"
     ]
    }
   ],
   "source": [
    "g = Graph(5)\n",
    "g.generate(25, 50)\n",
    "g.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will cover the implementation of the Approximate Vertex Cover which follows very closely to the algorithm given in the assignment brief. In this case, this cover takes an argument of type Graph (as defined earlier) and then finds the sets of all the edges in the Graph. \n",
    "\n",
    "Afterwards, a random edge is chosen and added to the output later on. A while loop runs as long as the edgeset is not empty. After that, we traverse the edgeset and find out which edges are touching the randomly chosen vertice and add it to the remove array. \n",
    "\n",
    "Lastly, we traverse this remove array to remove these edges from the set. After that, the while-loop runs again if the edgeset is not empty, the remove array is re-initialized, and the cycle repeats until the edgeset is empty. After that, the function returns a list of edges that make up the vertex cover.\n",
    "\n",
    "To run this function, Simply run the cell below the implementation. If this function works, it should return a non-unique vertex cover each time it is run that is not necessarily the minimum vertex cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def approx_vertex_cover(graph):\n",
    "    \"\"\"\n",
    "    graph - Graph with open Hash table\n",
    "    \n",
    "    Given an input graph, it prints the number of edges and\n",
    "    the edgeset that denotes the approximate vertex cover\n",
    "    solution. Solution should be non-unique.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    edgeset = set()\n",
    "    \n",
    "    # set of all edges\n",
    "    for i in range(graph.slots):\n",
    "        curr = graph.hash[i].head\n",
    "        while curr:\n",
    "            # append edges, not vertices\n",
    "            edgeset.add(curr.data[1])\n",
    "            curr = curr.next\n",
    "    \n",
    "    while (edgeset != set()):\n",
    "        # making random choices\n",
    "        (x_ran, y_ran) = random.choice(tuple(edgeset))\n",
    "        out.append((x_ran, y_ran))\n",
    "        remove = []\n",
    "        for (a, b) in edgeset:\n",
    "            if a == x_ran or b == x_ran or a == y_ran or b == y_ran:\n",
    "                remove.append((a, b))\n",
    "        \n",
    "        for edge in remove:\n",
    "            edgeset.remove(edge)\n",
    "    \n",
    "    print(\"Length of approx vertex cover is\", len(out))\n",
    "    print(\"Vertex cover is\",out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of approx vertex cover is 10\n",
      "Vertex cover is [(2, 21), (1, 14), (5, 19), (22, 24), (7, 10), (9, 15), (11, 17), (16, 23), (13, 20), (3, 8)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 21),\n",
       " (1, 14),\n",
       " (5, 19),\n",
       " (22, 24),\n",
       " (7, 10),\n",
       " (9, 15),\n",
       " (11, 17),\n",
       " (16, 23),\n",
       " (13, 20),\n",
       " (3, 8)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph(5)\n",
    "g.generate(25, 50)\n",
    "\n",
    "approx_vertex_cover(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "In this problem, we are required to perform radix sort on letters instead of numbers. For the most part, the implementation is very similar to what we did with numbers. However, there a few modifications to the code. \n",
    "\n",
    "In terms of Counting Sort for letters, there are a few differences. Firstly, instead of 10 possible digits (0- 9), we have 26 different possible characters **(small 'a' to small 'z')**. Since, our count array has 26 entries instead of 10. Furthermore, since count sort works on numbers, we need to convert our small letters to meaningful numbers somehow. This is done through **ord()**, which accepts a string of length 1 and returns the unicode code point representation. Hence,\n",
    "* ord(a) returns 97\n",
    "* ord(b) returns 98\n",
    "* ...\n",
    "* ord(y) returns 121\n",
    "* ord(z) returns 122\n",
    "From this, we know that the unicodes for small letters are consecutive. However, it starts from 97 and ends at 122. Since the counting array should be as small as possible to ensure that count sort works on O(n) time, we should make the count array a size of 26, not 122. This is done by shifting these unicode indexs by -97, which is defined in line 4 of the function count_sort_letters. Other than that, the main function does not change.\n",
    "\n",
    "In order to use this function, please input an array of strings that is to be sorted. Please note that this algorithm only sorts small letter characters. Correct examples include\n",
    "* [\"bob\", \"danvy\", \"unittests\", \"mathematics\", \"jewel\", \"gem\"]\n",
    "* [\"nancy\", \"dave\", \"zhao\", \"give\", \"job\", \"please\"]\n",
    "\n",
    "These are incorrect examples:\n",
    "* \"bob\", \"danvy\", \"unittests\", \"mathematics\", \"jewel\", \"gem\"\n",
    "* \"nancy\", \"dave\", \"zhao\", \"give\", \"job\", \"please\"\n",
    "* [\"2134\", \"AQUINAS\", \"Liberal\", \"Wine\"]\n",
    "\n",
    "The first 2 examples are incorrect because it is not instantiated inside a list. The last one is incorrect because it contains forbidden characters (numbers, capital letters, etc).\n",
    "\n",
    "To run the relevant functions, call radix_sort_letters and put in an array of strings consisting of small letters only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zeta', 'umbrella', 'rain', 'dog', 'digit', 'cat', 'bob']\n",
      "['unittests', 'mathematics', 'jewel', 'gem', 'danvy', 'bob']\n",
      "['z', 'l', 'i', 'f', 'e', 'b', 'a']\n",
      "['acb', 'abc', 'aaa']\n"
     ]
    }
   ],
   "source": [
    "def count_sort_letters(array, size, col, max_len):\n",
    "    out   = [0] * size \n",
    "    \n",
    "    # 26 for all 26 letters of the alphabet\n",
    "    count    = [0] * 26\n",
    "    \n",
    "    # Using this to shift Unicode by 97 to the left\n",
    "    # To make the count table as small as possible. \n",
    "    shift = ord('a') \n",
    "\n",
    "    for item in array: \n",
    "        if col < len(item):\n",
    "            # shift to the corresponding index in\n",
    "            # the count array\n",
    "            letter = ord(item[col]) - shift\n",
    "        else: \n",
    "            letter = 0\n",
    "        count[letter] += 1 \n",
    "    \n",
    "    # Add culminative counts\n",
    "    for i in range(len(count) - 1):   \n",
    "        count[i + 1] += count[i] \n",
    "    \n",
    "    # Performing count sorting\n",
    "    for item in array:\n",
    "        if col < len(item):\n",
    "            letter = ord(item[col]) - shift\n",
    "        else:\n",
    "            letter = 0\n",
    "        out[len(out) - count[letter]] = item\n",
    "        count[letter] -= 1\n",
    "    return out\n",
    "\n",
    "def radix_sort_letters(arr):\n",
    "    \"\"\"\n",
    "    arr - input array of strings \n",
    "    \n",
    "    Radix sort sorts the letters from the \n",
    "    rightmost letter to the leftmost letter.\n",
    "    \"\"\"\n",
    "    if arr == []:\n",
    "        return []\n",
    "    \n",
    "    max_col = len(max(arr, key = len)) \n",
    "    for col in reversed(range(max_col)): \n",
    "        array = count_sort_letters(arr, len(arr), col, max_col)\n",
    "    return array\n",
    "\n",
    "def radix_sort_letters(array):\n",
    "    \"\"\"\n",
    "    arr - input array of strings \n",
    "    \n",
    "    Radix sort sorts the letters from the \n",
    "    rightmost letter to the leftmost letter.\n",
    "    \"\"\"\n",
    "    max_col = len(max(array, key = len)) \n",
    "    for col in reversed(range(max_col)): \n",
    "        array = count_sort_letters(array, len(array), col, max_col)\n",
    "    return array\n",
    "\n",
    "print(radix_sort_letters([\"dog\", \"cat\", \"rain\", \"umbrella\", \"bob\", \"digit\", \"zeta\"]))\n",
    "print(radix_sort_letters([\"bob\", \"danvy\", \"unittests\", \"mathematics\", \"jewel\", \"gem\"]))\n",
    "print(radix_sort_letters([\"a\", \"z\", \"b\", \"l\", \"i\", \"e\", \"f\"]))\n",
    "print(radix_sort_letters([\"abc\", \"aaa\", \"acb\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "This question prompts us to implement a queue using 2 stacks. While this is possible, we will realize that we have to pay a cost in terms of runtime later on. Before beginning, let's recap on the nature of stacks and queues:\n",
    "* Stacks - FIFO. The first element pushed is the first element popped\n",
    "* Queue - LIFO. The last element enqueued becomes the first element to be dequeued\n",
    "\n",
    "With such a large difference in terms of FIFO and LIFO, to implement a stack using a queue, the second stack will become an auxillary stack that helps fulfill the requirements of a queue. \n",
    "\n",
    "In this implementation of the queue, I felt that it didn't really make sense to include a head and tail since the stack is handling all data manipulation, so I removed it. To begin with the implementation, I first used 2 stacks. In a sense, the first stack would be the main stack storing the queue while the second stack functions as a cache to reverse the order of a stack and pop the bottommost element for dequeuing, thereby fulfilling the requirements of a queue. We show the Stack first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stack:\n",
    "    def __init__(self, size):\n",
    "        self.items = [None] * size\n",
    "        self.top = 0\n",
    "        self.size = size\n",
    "    \n",
    "    def isEmpty(self):\n",
    "        return self.top == 0\n",
    "\n",
    "    def push(self, data):\n",
    "        if self.top >= self.size:\n",
    "            raise ValueError(\"Stack Overflow\")\n",
    "        self.items[self.top] = data\n",
    "        self.top += 1\n",
    "    \n",
    "    def pop(self):\n",
    "        if self.top <= 0:\n",
    "            raise ValueError(\"Stack Underflow\")\n",
    "        self.top -= 1\n",
    "        return self.items[self.top]\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"\n",
    "        Prints stack. The first element is the First element enqueued\n",
    "        which should be dequeued last. The last element is the last element \n",
    "        enqueued which should be dequeued first. \n",
    "        \"\"\"\n",
    "        temp = self.top\n",
    "        for i in range(0 ,temp):\n",
    "            print(self.items[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When implementing a Queue, we could choose to make either enqueuing or dequeuing costly. In this case, we choose the latter to be costly. For this case, we denote the 2 stacks as s1 (Main) and s2 (Auxillary). When enqueuing, we simply push the data into s1 for a O(1) operation. in the FIFO paradigm, this means that the element at the bottom of s1 should be removed when performing dequeuing.\n",
    "\n",
    "In this case, we define the top of stack s1 to be the first element in the queue. Since a queue is LIFO in nature, this means that. This element is the last to be out. Instead, the bottom element of stack 1 is removed during a dequeue. In this case, in order to remove this, we need to make this at the top of the stack. This is done by popping all elements in stack 1 and pushing them in order to stack 2. After this is done, then we pop off the first element in stack 2. This is doable because the elements in stack 2 are arranged in reverse order to stack 1.\n",
    "\n",
    "After this is done, all that is needed is to pop all the elements in stack 2 in order and push them back into stack 1, thereby preserving the order of the Queue. Hence, enqueuing is a O(1) operation but dequeuing is O(n) instead, which is rather costly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queue:\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        self.s1 = Stack(size)\n",
    "        self.s2 = Stack(size)\n",
    "        self.cache = 0 \n",
    "        self.size = size\n",
    "    \n",
    "    def enqueue(self, data):\n",
    "        \"\"\"\n",
    "        Normal, Bread and Butter enqueuing\n",
    "        That costs O(1)\n",
    "        \"\"\"\n",
    "        # check for overflow\n",
    "        self.cache += 1\n",
    "        if self.cache > self.size:\n",
    "            raise ValueError(\"Stack Overflow\")\n",
    "        self.s1.push(data)\n",
    "    \n",
    "    def dequeue(self):\n",
    "        \"\"\"\n",
    "        Costly dequeuing that costs O(n)\n",
    "        because element to be dequeued is \n",
    "        in Bottom of stack\n",
    "        \"\"\"\n",
    "        # check for underflow \n",
    "        self.cache -= 1\n",
    "        if self.cache < 0:\n",
    "            raise ValueError(\"Stack Underflow\")\n",
    "        \n",
    "        while not self.s1.isEmpty():\n",
    "            self.s2.push(self.s1.pop())\n",
    "        \n",
    "        item = self.s2.pop()\n",
    "        \n",
    "        while not self.s2.isEmpty():\n",
    "            self.s1.push(self.s2.pop())\n",
    "            \n",
    "        return item  \n",
    "    \n",
    "    def display(self):\n",
    "        self.s1.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section shows some of the tests I performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for underflow - uncomment to run\n",
    "# q = Queue(1)\n",
    "# q.dequeue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for overflow - uncomment to run\n",
    "# q = Queue(1)\n",
    "# q.enqueue(2)\n",
    "# q.enqueue(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "Dequeuing,  1\n",
      "Current queue: \n",
      "4\n",
      "3\n",
      "2\n",
      "Dequeuing,  2\n",
      "Current queue: \n",
      "4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 4 is added last\n",
    "# 1 is added first, should be removed upon dequeue\n",
    "# 2 is added second, should be removed upon second dequeue\n",
    "\n",
    "q = Queue_alt(4)\n",
    "q.enqueue(1)\n",
    "q.enqueue(2)\n",
    "q.enqueue(3)\n",
    "q.enqueue(4)\n",
    "q.display()\n",
    "print(\"Dequeuing, \", q.dequeue())\n",
    "print(\"Current queue: \")\n",
    "q.display()\n",
    "print(\"Dequeuing, \", q.dequeue())\n",
    "print(\"Current queue: \")\n",
    "q.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of defining Queues is by making the Enqueuing expensive (O(n) time) and Dequeuing (O(1) time) cheap. In this case, the top element of the queue become the last element added to the queue under the LIFO method, making it the first to be removed. On the other hand, the bottom element of the queue becomes the first element to be added to the queue. Therefore, when dequeuing, we simply remove the first element at the top of stack s1.\n",
    "\n",
    "However, for enqueuing, we have to reverse the stack order by popping all elements of s1 to p2, then pushing the new data into the stack. After that, we pop all the elements of s2 back to s1, and hence the new data becomes the bottom most element and the last to be removed as a result. By doing this, we preserve the LIFO preserve of queues. In this implementation, enqueuing takes O(n) time whild dequeuing takes O(1) time. \n",
    "\n",
    "We have established that implementing Queues using 2 stacks is much more costly than implementing a Queue itself. While it was a fun mental exercise, I think that the moral of the story is to use the most appropriate data structure to tackle problems and not reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queue_alt:\n",
    "    def __init__(self, size):\n",
    "        self.s1 = Stack(size)\n",
    "        self.s2 = Stack(size)\n",
    "        self.cache = 0 \n",
    "        self.size = size\n",
    "    \n",
    "    def enqueue(self, data):\n",
    "        \"\"\"\n",
    "        Costly enqueued that costs O(n)\n",
    "        because element to be enqueued is \n",
    "        in Bottom of stack\n",
    "        \"\"\"\n",
    "        # check for overflow\n",
    "        self.cache += 1\n",
    "        if self.cache > self.size:\n",
    "            raise ValueError(\"Stack Overflow\")\n",
    "        \n",
    "        while not self.s1.isEmpty():\n",
    "            self.s2.push(self.s1.pop())\n",
    "        \n",
    "        self.s2.push(data)\n",
    "        \n",
    "        while not self.s2.isEmpty():\n",
    "            self.s1.push(self.s2.pop())\n",
    "            \n",
    "        \n",
    "    def dequeue(self):\n",
    "        \"\"\"\n",
    "        Cheap dequeuing operation that costs\n",
    "        O(1) because element to be dequeued\n",
    "        is already at the top of the Stack\n",
    "        \"\"\"\n",
    "        # check for underflow \n",
    "        self.cache -= 1\n",
    "        if self.cache < 0:\n",
    "            raise ValueError(\"Stack Underflow\")\n",
    "        \n",
    "        item = self.s1.pop()\n",
    "            \n",
    "        return item  \n",
    "    \n",
    "    def display(self):\n",
    "        self.s1.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for underflow - uncomment to run\n",
    "# q = Queue_alt(1)\n",
    "# q.dequeue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for overflow - uncomment to run\n",
    "# q = Queue_alt(1)\n",
    "# q.enqueue(2)\n",
    "# q.enqueue(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "Dequeuing,  1\n",
      "Current queue: \n",
      "4\n",
      "3\n",
      "2\n",
      "Dequeuing,  2\n",
      "Current queue: \n",
      "4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 4 is added last\n",
    "# 1 is added first, should be removed upon dequeue\n",
    "# 2 is added second, should be removed upon second dequeue\n",
    "\n",
    "q = Queue_alt(4)\n",
    "q.enqueue(1)\n",
    "q.enqueue(2)\n",
    "q.enqueue(3)\n",
    "q.enqueue(4)\n",
    "q.display()\n",
    "print(\"Dequeuing, \", q.dequeue())\n",
    "print(\"Current queue: \")\n",
    "q.display()\n",
    "print(\"Dequeuing, \", q.dequeue())\n",
    "print(\"Current queue: \")\n",
    "q.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Before beginning this problem, allow me to import the random library which will be used frequently in this question, together with the constant LARGE_PRIME which is very important for universal hashing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "LARGE_PRIME = 10888869450418352160768000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we are required to implement an open has table that is under the SUHA and robust to adversarial attacks. \n",
    "\n",
    "Before going through these parts more in-depth, we know that the data of a hospital consists of its name, date of birth, IC and illness. With that in mind, we define a linked list and Node that takes in these attributes and perform some basic tests on it. The more in-depth functions will be defined in our universal Hash later on; this only serves as the rudimentary data structure for more complex functions. In this particular question, I feel that the more complex deletion and search functions shold be done on the Hash class because it worked out better for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name = None, dob = None, id_no = None, illness = None, next = None):\n",
    "        self.name = name\n",
    "        self.dob = dob\n",
    "        self.id_no = id_no\n",
    "        self.illness = illness\n",
    "        self.next = None\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "class LinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        \n",
    "    def insert(self, name, dob, id_no, illness):\n",
    "        new = Node(name, dob, id_no, illness)\n",
    "        new.next = self.head\n",
    "        self.head = new\n",
    "    \n",
    "    def display(self):\n",
    "        curr = self.head\n",
    "        index = 0\n",
    "        while curr:\n",
    "            print(\"Index:\", index, \", Name:\", curr.name, \", DOB:\", curr.dob, \", ID:\", curr.id_no, \", Illness:\", curr.illness)\n",
    "            index += 1\n",
    "            curr = curr.next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0 , Name: Mary , DOB: 2 Jun 2020 , ID: 9238412 , Illness: Cancer\n",
      "Index: 1 , Name: Bob , DOB: 23 May 1923 , ID: 1231243 , Illness: Tuberculosis\n"
     ]
    }
   ],
   "source": [
    "ll = LinkedList()\n",
    "ll.insert(\"Bob\", \"23 May 1923\", 1231243, \"Tuberculosis\")\n",
    "ll.insert(\"Mary\", \"2 Jun 2020\", 9238412, \"Cancer\")\n",
    "ll.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define a universal hash function that satisfies SUHA. This is done by defining a hash function using a very large prime number p as a proxy and making it adhere to this formula stated below:\n",
    "\n",
    "$$ H = ((A*Key + B) \\; mod \\; p ) mod \\; s$$\n",
    "This is where:\n",
    "* H is the Hashed value\n",
    "* p is the very large prime number\n",
    "* s is the number of slots in the universal hash\n",
    "* B is a random number from 1 to p - 1 inclusive\n",
    "* A is a random number from 0 to p - 1 inclusive\n",
    "* Key refers to the Unique ID that will be hashed\n",
    "\n",
    "The reason why the ID is chosen to be hashed is because it is unique, and our hashing function is deterministic. Hence, given the same ID key, we can find the value it is hashed to with definite certain because the hashing equation is fixed upon the initialization of the universal hash. This explains why there is a utility function **find_key** defined. \n",
    "\n",
    "In the initialization of UniversalHash as a class, you can observe that a, b, s, p all relate to the values I've put above. When initializing it, please the **LARGE_PRIME** in the prime parameter and input any number you deem fit to be the number of slots (more than 0, please...). This should take in name **(String)**, **date of birth(String)**, **Identity number(Integer)** and **Illness(String)**\n",
    "\n",
    "For the search and delete functions, defining it using ID is very easy because it is unique, and we can guarantee that the correct node will be deleted or search in O(keys/slots) time, which is very efficient. The Count_SUHA function will be discussed later on. However, for searching the names, illness and date of birth, it is not so trivial because these values are non-unique: more than 1 patient could have the same birthday, name or illness. Hence, it is not practical to return just one possible ID, but all the possible IDs that correspond to these values. This is why i defined these search functions as ones that return a list of possible ID values and not 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalHash:\n",
    "    def __init__(self, prime, slots):\n",
    "        self.a = random.randint(0, prime - 1)\n",
    "        self.b = random.randint(1, prime - 1)\n",
    "        self.s = slots\n",
    "        self.p = prime\n",
    "        self.info = {i: LinkedList() for i in range(self.s)}\n",
    "        \n",
    "    def find_key(self, id_no):\n",
    "        \"\"\"\n",
    "        function that converts the id_no to the corresponding\n",
    "        hash index in the universal hash.\n",
    "        \"\"\"\n",
    "        return ((self.a * id_no + self.b) % self.p) % self.s\n",
    "    \n",
    "    def display_hash(self, id_no):\n",
    "        \"\"\"\n",
    "        given an id number, it displays \n",
    "        the linked list associated with \n",
    "        its hash \n",
    "        \"\"\"\n",
    "        key = self.find_key(id_no)\n",
    "        self.info[key].display()\n",
    "    \n",
    "    def add(self, name, dob, id_no, illness):\n",
    "        index = self.find_key(id_no)\n",
    "        head = self.info[index]\n",
    "        head.insert(name, dob, id_no, illness)\n",
    "        \n",
    "    def search_id(self, key):\n",
    "        \"\"\"\n",
    "        Given an id number, it searches for whether the ID is found in the associated hash.\n",
    "        \"\"\"\n",
    "        index = self.find_key(key)\n",
    "        cur = self.info[index].head\n",
    "        while curr:\n",
    "            if curr.id_no == key:\n",
    "                print(\"Key found. returning Pointer\")\n",
    "                return curr\n",
    "            curr =  curr.next\n",
    "        print(\"Match not found. Returning None\")\n",
    "        return curr\n",
    "    \n",
    "    def delete_id(self, key):\n",
    "        \"\"\"\n",
    "        Given an ID_no, it locates\n",
    "        the hash it will be mapped \n",
    "        to and checks whether said \n",
    "        element exists. If yes, \n",
    "        then deletion is done. \n",
    "        \"\"\"\n",
    "        index = self.find_key(key)\n",
    "        curr = self.info[index].head\n",
    "        prev = None\n",
    "        while curr and curr.id_no != key:\n",
    "            prev = curr\n",
    "            curr = curr.next\n",
    "        \n",
    "        if curr is None:\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            remove = curr\n",
    "            if prev is None:\n",
    "                self.info[index].head = self.info[index].head.next\n",
    "            else:\n",
    "                prev.next = prev.next.next\n",
    "            return remove\n",
    "           \n",
    "        \n",
    "        \n",
    "    \n",
    "    def count_SUHA(self):\n",
    "        \"\"\"\n",
    "        Utility function to see\n",
    "        whether Hash table meets\n",
    "        SUHA by counting the number\n",
    "        of nodes in each slot and\n",
    "        returning as a dictionary\n",
    "        \"\"\"\n",
    "        out = {}\n",
    "        for i in range(self.s):\n",
    "            curr= self.info[i].head\n",
    "            count = 0 \n",
    "            while curr:\n",
    "                count += 1\n",
    "                curr = curr.next\n",
    "            out[i] = count\n",
    "        return out\n",
    "    \n",
    "    def search_name(self, key):\n",
    "        \"\"\"\n",
    "        Given a key name, search the\n",
    "        entire array for all possible\n",
    "        IDs corresponding to this DOB\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        for i in range(self.s):\n",
    "            curr = self.info[i].head\n",
    "            while curr:\n",
    "                if curr.name == key:\n",
    "                    out.append(curr.id_no)\n",
    "                curr = curr.next\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def search_dob(self, key):\n",
    "        \"\"\"\n",
    "        Given a key DOB, search the\n",
    "        entire array for all possible\n",
    "        IDs corresponding to this DOB\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        for i in range(self.s):\n",
    "            curr = self.info[i].head\n",
    "            while curr:\n",
    "                if curr.dob == key:\n",
    "                    out.append(curr.id_no)\n",
    "                curr = curr.next\n",
    "        return out\n",
    "    \n",
    "    def search_illness(self, key):\n",
    "        \"\"\"\n",
    "        Given a key illness, search the\n",
    "        entire array for all possible IDs\n",
    "        corresponding to this illness\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        for i in range(self.s):\n",
    "            curr = self.info[i].head\n",
    "            while curr:\n",
    "                if curr.illness == key:\n",
    "                    out.append(curr.id_no)\n",
    "                curr = curr.next\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test for SUHA, we perform a rather extreme test on the hash function: given 1000000 keys, we assign each of them to a random ID from 0 to 10^8. Afterwards, we check whether this number was used (If it is, we restart since ID is unique). If not, we add this ID to our hash function. After that, we check the number of nodes/ entries in each slot using **count_SUHA()** and check whether they are roughly equal to **trials/slots** (which is printed near the end). If this holds, we know that the SUHA assumption is fulfilled. Run the function below. As you can see, the exact ratio is very close to the number of nodes in each of the slots. Therefore, SUHA is fulfilled and resistant to adversial attacks against efficiency (as seen from the wide range of random numbers generated). To run the **test_SUHA** function, just run the below line and modify the number of slots as you deem fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 19978, 1: 20159, 2: 20044, 3: 20011, 4: 19983, 5: 20190, 6: 20037, 7: 20145, 8: 19819, 9: 19893, 10: 19711, 11: 20113, 12: 19891, 13: 19967, 14: 19985, 15: 20072, 16: 20006, 17: 20250, 18: 20202, 19: 19829, 20: 20149, 21: 20084, 22: 19984, 23: 19983, 24: 19958, 25: 19935, 26: 19913, 27: 19941, 28: 19588, 29: 19965, 30: 20185, 31: 19827, 32: 19876, 33: 19987, 34: 19977, 35: 20009, 36: 19930, 37: 20149, 38: 20107, 39: 20176, 40: 19906, 41: 19898, 42: 20109, 43: 19933, 44: 19902, 45: 20110, 46: 20108, 47: 20080, 48: 19943, 49: 20004}\n",
      "Exact ratio of keys to slots is:  20000.0\n"
     ]
    }
   ],
   "source": [
    "def test_SUHA(slots):\n",
    "    p = UniversalHash(LARGE_PRIME, slots)\n",
    "    limit = 10 ** 8\n",
    "    keys = 10 ** 6\n",
    "    trials = keys\n",
    "    used_id = set()\n",
    "    while trials >= 0:\n",
    "        random_number = random.randint(0, limit)\n",
    "        if random_number in used_id:\n",
    "            continue\n",
    "        else:\n",
    "            p.add(\"dummy_name\", \"dummy_dob\", random_number, \"dummy_illness\")\n",
    "            used_id.add(random_number)\n",
    "            trials -= 1\n",
    "\n",
    "    test = p.count_SUHA()\n",
    "    print(test)\n",
    "    print(\"Exact ratio of keys to slots is: \", keys/slots)\n",
    "    return\n",
    "\n",
    "test_SUHA(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells detail tests relating to the auxillary functions of my Universal Hash function. With these in mind, my functions have passed preliminary tests to become actually usable functions.\n",
    "\n",
    "To use the search functions, simply call the related search function and search the desired value. Please use int for id_no and str for the rest of the data types and ensure that your spelling is correct for the strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing display_hash...\n",
      "Index: 0 , Name: Bob , DOB: 25 May 1998 , ID: 2125123 , Illness: Fever\n",
      "\n",
      "Testing Delete...\n",
      "\n",
      "Testing search_dob...\n",
      "[7842355, 9826312]\n",
      "\n",
      "Testing search_illness...\n",
      "[3451623, 2246713, 2982641]\n",
      "\n",
      "Testing search_name...\n",
      "[5628395, 1092752, 8264912]\n"
     ]
    }
   ],
   "source": [
    "p = UniversalHash(LARGE_PRIME, 20)\n",
    "p.add(\"Bob\", \"25 May 1998\", 2125123, \"Fever\")\n",
    "p.add(\"Mary\", \"28 Feb 1992\", 1235124, \"Tuberculosis\")\n",
    "\n",
    "print(\"\\nTesting display_hash...\")\n",
    "p.display_hash(2125123)\n",
    "\n",
    "print(\"\\nTesting Delete...\")\n",
    "p.delete_id(2125123)\n",
    "p.display_hash(2125123)\n",
    "\n",
    "print(\"\\nTesting search_dob...\")\n",
    "p.add(\"Carry\", \"25 May 1998\", 7842355, \"AIDS\")\n",
    "p.add(\"Rachel\", \"25 May 1998\", 9826312, \"Parkinsons'\")\n",
    "print(p.search_dob(\"25 May 1998\"))\n",
    "\n",
    "print(\"\\nTesting search_illness...\")\n",
    "p.add(\"Megan\", \"31 Dec 1978\", 2246713, \"Hay Fever\")\n",
    "p.add(\"Sandra\", \"13 Mar 1987\", 3451623, \"Hay Fever\")\n",
    "p.add(\"Achsah\", \"4 Feb 1990\", 2982641, \"Hay Fever\")\n",
    "print(p.search_illness(\"Hay Fever\"))\n",
    "\n",
    "print(\"\\nTesting search_name...\")\n",
    "p.add(\"John\", \"31 Jul 1991\", 5628395, \"Constipation\")\n",
    "p.add(\"John\", \"31 Dec 1983\", 8264912, \"Depression\")\n",
    "p.add(\"John\", \"23 May 1964\", 1092752, \"Workplace Injury\")\n",
    "print(p.search_name(\"John\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
